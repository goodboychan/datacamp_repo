{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Regular Expression Concepts\n",
    "\n",
    "> In the last step of your journey, you will learn more complex methods of pattern matching using parentheses to group strings together or to match the same text as matched previously. Also, you will get an idea of how you can look around expressions. This is the Summary of lecture \"Regular Expressions in Python\", via datacamp.\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- author: Chanseok Kang\n",
    "- categories: [Python, Datacamp]\n",
    "- image: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capturing groups\n",
    "- Capturing groups\n",
    "    - Match a specific subpattern in a pattern\n",
    "    - Organize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try another name\n",
    "You are still working on your Twitter sentiment analysis. You analyze now some things that caught your attention. You noticed that there are email addresses inserted in some tweets. Now, you are curious to find out which is the most common name.\n",
    "\n",
    "You want to extract the first part of the email. E.g. if you have the email `marysmith90@gmail.com`, you are only interested in `marysmith90`.\n",
    "You need to match the entire expression. So you make sure to extract only names present in emails. Also, you are only interested in names containing upper (e.g. A,B, Z) or lowercase letters (e.g. a, d, z) and numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis = ['Just got ur newsletter, those fares really are unbelievable. Write to statravelAU@gmail.com or statravelpo@hotmail.com. They have amazing prices',\n",
    " 'I should have paid more attention when we covered photoshop in my webpage design class in undergrad. Contact me Hollywoodheat34@msn.net.',\n",
    " 'hey missed ya at the meeting. Read your email! msdrama098@hotmail.com']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lists of users found in this tweet: ['statravelAU', 'statravelpo']\n",
      "Lists of users found in this tweet: ['Hollywoodheat34']\n",
      "Lists of users found in this tweet: ['msdrama098']\n"
     ]
    }
   ],
   "source": [
    "# Write a regex that matches email\n",
    "regex_email = r\"([a-zA-Z0-9]+)@\\S+\"\n",
    "\n",
    "for tweet in sentiment_analysis:\n",
    "    # Find all matches of regex in each tweet\n",
    "    email_matched = re.findall(regex_email, tweet)\n",
    "    \n",
    "    # Complete the format method to print the results\n",
    "    print(\"Lists of users found in this tweet: {}\".format(email_matched))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flying home\n",
    "Your boss assigned you to a small project. They are performing an analysis of the travels people made to attend business meetings. You are given a dataset with only the email subjects for each of the people traveling.\n",
    "\n",
    "You learn that the text followed a pattern. Here is an example:\n",
    "\n",
    "`Here you have your boarding pass LA4214 AER-CDB 06NOV.`\n",
    "\n",
    "You need to extract the information about the flight:\n",
    "\n",
    "- The two letters indicate the airline (e.g `LA`),\n",
    "- The 4 numbers are the flight number (e.g. `4214`).\n",
    "- The three letters correspond to the departure (e.g `AER`),\n",
    "- The destination (`CDB`),\n",
    "- The date (`06NOV`) of the flight.\n",
    "\n",
    "All letters are always uppercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight = 'Subject: You are now ready to fly. Here you have your boarding pass IB3723 AMS-MAD 06OCT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Airline: IB Flight number: 3723\n",
      "Departure: AMS Destination: MAD\n",
      "Date: 06OCT\n"
     ]
    }
   ],
   "source": [
    "# Write regex to capture information of the flight\n",
    "regex = r\"([A-Z]{2})(\\d{4})\\s([A-Z]{3})-([A-Z]{3})\\s(\\d{2}[A-Z]{3})\"\n",
    "\n",
    "# Find all matches of the flight information\n",
    "flight_matches = re.findall(regex, flight)\n",
    "\n",
    "# Print the matches\n",
    "print(\"Airline: {} Flight number: {}\".format(flight_matches[0][0], flight_matches[0][1]))\n",
    "print(\"Departure: {} Destination: {}\".format(flight_matches[0][2], flight_matches[0][3]))\n",
    "print(\"Date: {}\".format(flight_matches[0][4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternation and non-capturing groups\n",
    "- Alternation\n",
    "    - Use groups to choose between optional patterns\n",
    "    - Use non-capturing groups for alternation\n",
    "- Non-capturing group\n",
    "    - Match but not capture a group\n",
    "        - When group is not backreferenced\n",
    "        - Add `?:` : `(?:regex)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Love it!\n",
    "You are still working on the Twitter sentiment analysis project. First, you want to identify positive tweets about movies and concerts.\n",
    "\n",
    "You plan to find all the sentences that contain the words love, like, or enjoy and capture that word. You will limit the tweets by focusing on those that contain the words movie or concert by keeping the word in another group. You will also save the movie or concert name.\n",
    "\n",
    "For example, if you have the sentence: `I love the movie Avengers`. You match and capture `love`. You need to match and capture movie. Afterwards, you match and capture anything until the dot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis = ['I totally love the concert The Book of Souls World Tour. It kinda amazing!',\n",
    " 'I enjoy the movie Wreck-It Ralph. I watched with my boyfriend.',\n",
    " \"I still like the movie Wish Upon a Star. Too bad Disney doesn't show it anymore.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive comments found [('like', 'movie', ' The cabin and the ant')]\n",
      "Positive comments found []\n",
      "Positive comments found [('like', 'concert', ' After twelve Tour')]\n"
     ]
    }
   ],
   "source": [
    "# Write a regex that matches sentences with the optional words\n",
    "regex_positive = r\"(love|like|enjoy).+?\\s(movie|concert)(.+?)\\.\"\n",
    "\n",
    "for tweet in sentiment_analysis:\n",
    "    # Find all matches of regex in tweet\n",
    "    positive_matches = re.findall(regex_positive, tweet)\n",
    "    \n",
    "    # Complete format to print out the results\n",
    "    print('Positive comments found {}'.format(positive_matches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ugh! Not for me!\n",
    "After finding positive tweets, you want to do it for negative tweets. Your plan now is to find sentences that contain the words hate, dislike or disapprove. You will again save the movie or concert name. You will get the tweet containing the words movie or concert but this time, you don't plan to save the word.\n",
    "\n",
    "For example, if you have the sentence: `I dislike the movie Avengers a lot.`. You match and capture `dislike`. You will match but not capture the word `movie`. Afterwards, you match and capture anything until the dot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis = ['That was horrible! I really dislike the movie The cabin and the ant. So boring.',\n",
    " \"I disapprove the movie Honest with you. It's full of cliches.\",\n",
    " 'I dislike very much the concert After twelve Tour. The sound was horrible.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative comments found [('dislike', ' The cabin and the ant')]\n",
      "Negative comments found [('disapprove', ' Honest with you')]\n",
      "Negative comments found [('dislike', ' After twelve Tour')]\n"
     ]
    }
   ],
   "source": [
    "# Write a regex that matches sentences with the optional words\n",
    "regex_negative = r\"(hate|dislike|disapprove).+?\\s(?:movie|concert)(.+?)\\.\"\n",
    "\n",
    "for tweet in sentiment_analysis:\n",
    "    # Find all matches of regex in tweet\n",
    "    negative_matches = re.findall(regex_negative, tweet)\n",
    "    \n",
    "    # Complete format to print out the results\n",
    "    print(\"Negative comments found {}\".format(negative_matches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backreferences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing PDF files\n",
    "You now need to work on another small project you have been delaying. Your company gave you some PDF files of signed contracts. The goal of the project is to create a database with the information you parse from them. Three of these columns should correspond to the day, month, and year when the contract was signed.\n",
    "The dates appear as `Signed on 05/24/2016` (`05` indicating the month, `24` the day). You decide to use capturing groups to extract this information. Also, you would like to retrieve that information so you can store it separately in different variables.\n",
    "\n",
    "You decide to do a proof of concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "contract = 'Provider will invoice Client for Services performed within 30 days of performance.  Client will pay Provider as set forth in each Statement of Work within 30 days of receipt and acceptance of such invoice. It is understood that payments to Provider for services rendered shall be made in full as agreed, without any deductions for taxes of any kind whatsoever, in conformity with Providerâ€™s status as an independent contractor. Signed on 03/25/2001.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our first contract is dated back to 2001. Particularly, the day 25 of the month 03.\n"
     ]
    }
   ],
   "source": [
    "# Write regex and scan contract to capture the dates described\n",
    "regex_dates = r\"Signed\\son\\s(\\d{2})/(\\d{2})/(\\d{4})\"\n",
    "dates = re.search(regex_dates, contract)\n",
    "\n",
    "# Assign to each key the corresponding match\n",
    "signature = {\n",
    "    \"day\":dates.group(2),\n",
    "    \"month\":dates.group(1),\n",
    "    \"year\":dates.group(3)\n",
    "}\n",
    "\n",
    "# Complete the format method to print-out\n",
    "print(\"Our first contract is dated back to {data[year]}. Particularly, the day {data[day]} of the month {data[month]}.\".format(data=signature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close the tag, please!\n",
    "In the meantime, you are working on one of your other projects. The company is going to develop a new product. It will help developers automatically check the code they are writing. You need to write a short script for checking that every HTML tag that is open has its proper closure.\n",
    "\n",
    "You have an example of a string containing HTML tags:\n",
    "```html\n",
    "<title>The Data Science Company</title>\n",
    "```\n",
    "You learn that an opening HTML tag is always at the beginning of the string. It appears inside `<>`. A closing tag also appears inside `<>`, but it is preceded by `/`.\n",
    "\n",
    "You also remember that capturing groups can be referenced using numbers, e.g `\\4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_tags = ['<body>Welcome to our course! It would be an awesome experience</body>',\n",
    " '<article>To be a data scientist, you need to have knowledge in statistics and mathematics</article>',\n",
    " '<nav>About me Links Contact me!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your tag body is closed\n",
      "Your tag article is closed\n",
      "Close your nav tag!\n"
     ]
    }
   ],
   "source": [
    "for string in html_tags:\n",
    "    # complete the regex and find if it matches a closed HTML tags\n",
    "    match_tag = re.match(r\"<(\\w+)>.*?</\\1>\", string)\n",
    "    \n",
    "    if match_tag:\n",
    "        # If it matches print the first group capture\n",
    "        print(\"Your tag {} is closed\".format(match_tag.group(1)))\n",
    "    else:\n",
    "        # If it doesn't match capture only the tag\n",
    "        notmatch_tag = re.match(r\"<(\\w+)>\", string)\n",
    "        # Print the first group capture\n",
    "        print(\"Close your {} tag!\".format(notmatch_tag.group(1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reeepeated characters\n",
    "Back to your sentiment analysis! Your next task is to replace elongated words that appear in the tweets. We define an elongated word as a word that contains a repeating character twice or more times. e.g. \"Awesoooome\".\n",
    "\n",
    "Replacing those words is very important since a classifier will treat them as a different term from the source words lowering their frequency.\n",
    "\n",
    "To find them, you will use capturing groups and reference them back using numbers. E.g \\4.\n",
    "\n",
    "If you want to find a match for `Awesoooome`. You first need to capture `Awes`. Then, match `o` and reference the same character back, and then, `me`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis = ['@marykatherine_q i know! I heard it this morning and wondered the same thing. Moscooooooow is so behind the times',\n",
    " 'Staying at a friends house...neighborrrrrrrs are so loud-having a party',\n",
    " 'Just woke up an already have read some e-mail']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elongated word found: Moscooooooow\n",
      "Elongated word found: neighborrrrrrrs\n",
      "No elongated word found\n"
     ]
    }
   ],
   "source": [
    "# Complete the regex to match an elongated word\n",
    "regex_elongated = r\"\\w*(\\w)+\\1\\w*\"\n",
    "\n",
    "for tweet in sentiment_analysis:\n",
    "    # Find if there is a match in each tweet\n",
    "    match_elongated = re.search(regex_elongated, tweet)\n",
    "    \n",
    "    if match_elongated:\n",
    "        # Assign the captured group zero\n",
    "        elongated_word = match_elongated.group(0)\n",
    "        # Complete the format method to print the word\n",
    "        print(\"Elongated word found: {word}\".format(word=elongated_word))\n",
    "    else:\n",
    "        print(\"No elongated word found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lookaround\n",
    "- Looking around\n",
    "    - Allow us to confirm that sub-pattern is ahead or behind main patter\n",
    "    \n",
    "    - At my current position in the matching process, look ahead or behind and examine whether some pattern matches or not match before continuing\n",
    "- Look-ahead\n",
    "    - Non-capturing group\n",
    "    - Checks that the first part of the expression is followed (positive) or not (negative) by the lookahead expression\n",
    "    - Return only the first part of the expression\n",
    "- Look-behind\n",
    "    - Non-capturing group\n",
    "    - Get all the matches that are preceded or not by a specific pattern\n",
    "    - Return pattern after look-behind expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Surrounding words\n",
    "Now, you want to perform some visualizations with your `sentiment_analysis` dataset. You are interested in the words surrounding `python`. You want to count how many times a specific words appears right before and after it.\n",
    "\n",
    "**Positive lookahead** `(?=)` makes sure that first part of the expression is followed by the lookahead expression. **Positive lookbehind** `(?<=)` returns all matches that are preceded by the specified pattern.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis = 'You need excellent python skills to be a data scientist. Must be! Excellent python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['excellent', 'Excellent']\n"
     ]
    }
   ],
   "source": [
    "# Positive lookahead\n",
    "look_ahead = re.findall(r\"\\w+(?=\\spython)\", sentiment_analysis)\n",
    "\n",
    "# Print out\n",
    "print(look_ahead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['skills']\n"
     ]
    }
   ],
   "source": [
    "# Positive lookbehind\n",
    "look_behind = re.findall(r\"(?<=[Pp]ython\\s)\\w+\", sentiment_analysis)\n",
    "\n",
    "# Print out\n",
    "print(look_behind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering phone numbers\n",
    "Now, you need to write a script for a cell-phone searcher. It should scan a list of phone numbers and return those that meet certain characteristics.\n",
    "\n",
    "The phone numbers in the list have the structure:\n",
    "\n",
    "- Optional area code: 3 numbers\n",
    "- Prefix: 4 numbers\n",
    "- Line number: 6 numbers\n",
    "- Optional extension: 2 numbers\n",
    "\n",
    "E.g. `654-8764-439434-01`.\n",
    "\n",
    "You decide to use `.findall()` and the non-capturing group's negative lookahead `(?!)` and negative lookbehind `(?<!)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cellphones = ['4564-646464-01', '345-5785-544245', '6476-579052-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4564-646464-01']\n",
      "[]\n",
      "['6476-579052-01']\n"
     ]
    }
   ],
   "source": [
    "for phone in cellphones:\n",
    "    # Get all phone numbers not preceded by area code\n",
    "    number = re.findall(r\"(?<!\\d{3}-)\\d{4}-\\d{6}-\\d{2}\", phone)\n",
    "    print(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['345-5785-544245']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for phone in cellphones:\n",
    "    # Get all phone numbers not followed by optional extension\n",
    "    number = re.findall(r\"\\d{3}-\\d{4}-\\d{6}(?!-\\d{2})\", phone)\n",
    "    print(number)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
